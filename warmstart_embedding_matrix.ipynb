{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b6a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 11:20:49.219301: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad843f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 1186s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['README', 'imdbEr.txt', 'imdb.vocab', 'test', 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    \"aclImdb_v1.tar.gz\", url, untar=True, cache_dir=\".\", cache_subdir=\"\"\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fd15c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'urls_unsup.txt',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_pos.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c27959",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6301bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 11:43:52.256256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.277157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.277306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.277745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 11:43:52.278315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.278470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.278596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.698094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.698245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.698361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 11:43:52.698468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 252 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    ")\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0ee0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092cd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee036e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/spark/miniconda3/envs/recommend/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Make a text-only dataset (no labels) and call `Dataset.adapt` to build the\n",
    "# vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47357c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "text_embedding = Embedding(vocab_size, embedding_dim, name=\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689c6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.Sequential(\n",
    "    [vectorize_layer, text_embedding], name=\"text_input\"\n",
    ")\n",
    "classifier_head = tf.keras.Sequential(\n",
    "    [GlobalAveragePooling1D(), Dense(16, activation=\"relu\"), Dense(1)],\n",
    "    name=\"classifier_head\",\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([text_input, classifier_head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d5655b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "341da75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c59bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:57.323581: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f03a420e9d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-19 13:02:57.323599: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2023-04-19 13:02:57.326655: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-19 13:02:57.374074: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:57.401794: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-04-19 13:02:57.451980: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/20 [>.............................] - ETA: 25s - loss: 0.6932 - accuracy: 0.4961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:57.581629: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:57.671221: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/20 [===>..........................] - ETA: 2s - loss: 0.6931 - accuracy: 0.5124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:57.806659: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:57.930424: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/20 [========>.....................] - ETA: 1s - loss: 0.6930 - accuracy: 0.5023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:58.053764: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:58.203754: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/20 [============>.................] - ETA: 1s - loss: 0.6929 - accuracy: 0.5018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:58.329870: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:58.481489: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/20 [===============>..............] - ETA: 0s - loss: 0.6927 - accuracy: 0.5025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:58.603141: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:58.724688: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/20 [==================>...........] - ETA: 0s - loss: 0.6926 - accuracy: 0.5052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:58.845046: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:58.963784: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/20 [=====================>........] - ETA: 0s - loss: 0.6924 - accuracy: 0.5053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:59.083380: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:59.203013: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20 [========================>.....] - ETA: 0s - loss: 0.6923 - accuracy: 0.5053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:59.323800: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:59.446345: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:59.568726: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-04-19 13:02:59.688984: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "20/20 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 13:02:59.802423: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 126ms/step - loss: 0.6921 - accuracy: 0.5028 - val_loss: 0.6904 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6878 - accuracy: 0.5028 - val_loss: 0.6850 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.6806 - accuracy: 0.5028 - val_loss: 0.6765 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6694 - accuracy: 0.5028 - val_loss: 0.6638 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6534 - accuracy: 0.5028 - val_loss: 0.6462 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6314 - accuracy: 0.5028 - val_loss: 0.6236 - val_accuracy: 0.4888\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.6043 - accuracy: 0.5281 - val_loss: 0.5974 - val_accuracy: 0.5580\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.5730 - accuracy: 0.6195 - val_loss: 0.5678 - val_accuracy: 0.6312\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.5387 - accuracy: 0.6893 - val_loss: 0.5383 - val_accuracy: 0.6750\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.5049 - accuracy: 0.7379 - val_loss: 0.5108 - val_accuracy: 0.7132\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4730 - accuracy: 0.7689 - val_loss: 0.4862 - val_accuracy: 0.7386\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4441 - accuracy: 0.7928 - val_loss: 0.4652 - val_accuracy: 0.7570\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4184 - accuracy: 0.8107 - val_loss: 0.4475 - val_accuracy: 0.7656\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3957 - accuracy: 0.8245 - val_loss: 0.4329 - val_accuracy: 0.7762\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3756 - accuracy: 0.8365 - val_loss: 0.4208 - val_accuracy: 0.7866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04a50a0e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9f504f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c08dc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights_base = (\n",
    "    model.get_layer(\"text_input\").get_layer(\"embedding\").get_weights()[0]\n",
    ")\n",
    "vocab_base = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1dd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size_new = 10200\n",
    "sequence_length = 100\n",
    "\n",
    "vectorize_layer_new = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size_new,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer_new.adapt(text_ds)\n",
    "\n",
    "# Get the new vocabulary\n",
    "vocab_new = vectorize_layer_new.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0fb364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bullying',\n",
       " 'bumps',\n",
       " 'canvas',\n",
       " 'carole',\n",
       " 'chains',\n",
       " 'chairman',\n",
       " 'checks',\n",
       " 'coarse',\n",
       " 'competitive',\n",
       " 'component',\n",
       " 'compound',\n",
       " 'confirm',\n",
       " 'contemplate',\n",
       " 'coping',\n",
       " 'corporations',\n",
       " 'costuming',\n",
       " 'counterpart',\n",
       " 'crop',\n",
       " 'custody',\n",
       " 'cyborgs',\n",
       " 'daft',\n",
       " 'danced',\n",
       " 'daphne',\n",
       " 'darkest',\n",
       " 'davids',\n",
       " 'december',\n",
       " 'declared',\n",
       " 'defence',\n",
       " 'delve',\n",
       " 'demonstration',\n",
       " 'dense',\n",
       " 'denver',\n",
       " 'devilish',\n",
       " 'devious',\n",
       " 'dickinson',\n",
       " 'digs',\n",
       " 'directorwriter',\n",
       " 'download',\n",
       " 'effortless',\n",
       " 'electricity',\n",
       " 'elliot',\n",
       " 'enlightenment',\n",
       " 'erratic',\n",
       " 'exceedingly',\n",
       " 'eyeballs',\n",
       " 'fearless',\n",
       " 'fenton',\n",
       " 'fiennes',\n",
       " 'filter',\n",
       " 'fireworks',\n",
       " 'flipping',\n",
       " 'float',\n",
       " 'foggy',\n",
       " 'forgivable',\n",
       " 'framework',\n",
       " 'fulllength',\n",
       " 'funds',\n",
       " 'gamut',\n",
       " 'geeks',\n",
       " 'glee',\n",
       " 'goo',\n",
       " 'gripe',\n",
       " 'hardest',\n",
       " 'harmony',\n",
       " 'henchman',\n",
       " 'heritage',\n",
       " 'hg',\n",
       " 'hi',\n",
       " 'hightech',\n",
       " 'homework',\n",
       " 'houston',\n",
       " 'howards',\n",
       " 'hunger',\n",
       " 'imho',\n",
       " 'immigrants',\n",
       " 'improvised',\n",
       " 'impulse',\n",
       " 'inch',\n",
       " 'interpret',\n",
       " 'intimidating',\n",
       " 'iowa',\n",
       " 'jaffar',\n",
       " 'jeep',\n",
       " 'jock',\n",
       " 'kriemhild',\n",
       " 'kristofferson',\n",
       " 'lassie',\n",
       " 'laughoutloud',\n",
       " 'lennon',\n",
       " 'librarian',\n",
       " 'liza',\n",
       " 'locker',\n",
       " 'lommel',\n",
       " 'loren',\n",
       " 'lowered',\n",
       " 'marital',\n",
       " 'martins',\n",
       " 'mastroianni',\n",
       " 'megan',\n",
       " 'melt',\n",
       " 'mischievous',\n",
       " 'monstrosity',\n",
       " 'monumental',\n",
       " 'morse',\n",
       " 'mostel',\n",
       " 'muddy',\n",
       " 'noah',\n",
       " 'noirs',\n",
       " 'nostril',\n",
       " 'numbing',\n",
       " 'occupation',\n",
       " 'oceans',\n",
       " 'onesided',\n",
       " 'opus',\n",
       " 'organ',\n",
       " 'osullivan',\n",
       " 'otoole',\n",
       " 'overnight',\n",
       " 'parisian',\n",
       " 'partial',\n",
       " 'patriotism',\n",
       " 'pbs',\n",
       " 'penchant',\n",
       " 'penguin',\n",
       " 'plotted',\n",
       " 'powerfully',\n",
       " 'pows',\n",
       " 'practicing',\n",
       " 'prehistoric',\n",
       " 'prestigious',\n",
       " 'prevalent',\n",
       " 'prevents',\n",
       " 'profits',\n",
       " 'promotion',\n",
       " 'puke',\n",
       " 'pulse',\n",
       " 'punchline',\n",
       " 'quarters',\n",
       " 'rainer',\n",
       " 'ranting',\n",
       " 'rapists',\n",
       " 'rapture',\n",
       " 'rarity',\n",
       " 'rays',\n",
       " 'recommending',\n",
       " 'redeemed',\n",
       " 'refuge',\n",
       " 'refugee',\n",
       " 'relates',\n",
       " 'religions',\n",
       " 'remaking',\n",
       " 'renee',\n",
       " 'reply',\n",
       " 'restoration',\n",
       " 'resurrection',\n",
       " 'retreat',\n",
       " 'retro',\n",
       " 'rockets',\n",
       " 'romano',\n",
       " 'rooker',\n",
       " 'rooted',\n",
       " 'runtime',\n",
       " 'sap',\n",
       " 'scarred',\n",
       " 'secluded',\n",
       " 'selfabsorbed',\n",
       " 'separation',\n",
       " 'shattered',\n",
       " 'shenanigans',\n",
       " 'shootings',\n",
       " 'shue',\n",
       " 'silk',\n",
       " 'sm',\n",
       " 'soooo',\n",
       " 'spoton',\n",
       " 'sr',\n",
       " 'staple',\n",
       " 'stepfather',\n",
       " 'stoic',\n",
       " 'stud',\n",
       " 'suite',\n",
       " 'swanson',\n",
       " 'sweetness',\n",
       " 'sybil',\n",
       " 'tease',\n",
       " 'technological',\n",
       " 'tensions',\n",
       " 'theft',\n",
       " 'therapist',\n",
       " 'threats',\n",
       " 'tin',\n",
       " 'towel',\n",
       " 'transform',\n",
       " 'travelling',\n",
       " 'troupe',\n",
       " 'unremarkable',\n",
       " 'unsatisfied',\n",
       " 'untrue',\n",
       " 'vertigo',\n",
       " 'vic'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the new vocabulary tokens that weren't in `vocab_base`\n",
    "set(vocab_base) ^ set(vocab_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc205d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the updated embedding matrix\n",
    "updated_embedding = tf.keras.utils.warmstart_embedding_matrix(\n",
    "    base_vocabulary=vocab_base,\n",
    "    new_vocabulary=vocab_new,\n",
    "    base_embeddings=embedding_weights_base,\n",
    "    new_embeddings_initializer=\"uniform\",\n",
    ")\n",
    "# Update the model variable\n",
    "updated_embedding_variable = tf.Variable(updated_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9a42d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10200, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_embedding_variable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8d9ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_input_new\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 100)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 16)           163200    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,200\n",
      "Trainable params: 163,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10200, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embedding_layer_new = Embedding(\n",
    "    vectorize_layer_new.vocabulary_size(), embedding_dim, name=\"embedding\"\n",
    ")\n",
    "text_embedding_layer_new.build(input_shape=[None])\n",
    "text_embedding_layer_new.embeddings.assign(updated_embedding)\n",
    "text_input_new = tf.keras.Sequential(\n",
    "    [vectorize_layer_new, text_embedding_layer_new], name=\"text_input_new\"\n",
    ")\n",
    "text_input_new.summary()\n",
    "\n",
    "# Verify the shape of updated weights\n",
    "# The new weights shape should reflect the new vocabulary size\n",
    "text_input_new.get_layer(\"embedding\").get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "876cd48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_input_new (Sequential)  (None, 100, 16)          163200    \n",
      "                                                                 \n",
      " classifier_head (Sequential  (None, 1)                289       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,489\n",
      "Trainable params: 163,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "warm_started_model = tf.keras.Sequential([text_input_new, classifier_head])\n",
    "warm_started_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98f35b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True], shape=(16,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# New vocab words\n",
    "base_vocab_index = vectorize_layer(\"the\")[0]\n",
    "new_vocab_index = vectorize_layer_new(\"the\")[0]\n",
    "print(\n",
    "    warm_started_model.get_layer(\"text_input_new\").get_layer(\"embedding\")(\n",
    "        new_vocab_index\n",
    "    )\n",
    "    == embedding_weights_base[base_vocab_index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa7f360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.3597 - accuracy: 0.8437 - val_loss: 0.4119 - val_accuracy: 0.7946\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3452 - accuracy: 0.8507 - val_loss: 0.4045 - val_accuracy: 0.7998\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3325 - accuracy: 0.8571 - val_loss: 0.3982 - val_accuracy: 0.8056\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3208 - accuracy: 0.8625 - val_loss: 0.3930 - val_accuracy: 0.8070\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3099 - accuracy: 0.8676 - val_loss: 0.3887 - val_accuracy: 0.8118\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2998 - accuracy: 0.8728 - val_loss: 0.3853 - val_accuracy: 0.8132\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2903 - accuracy: 0.8777 - val_loss: 0.3827 - val_accuracy: 0.8140\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2813 - accuracy: 0.8819 - val_loss: 0.3807 - val_accuracy: 0.8176\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2729 - accuracy: 0.8856 - val_loss: 0.3793 - val_accuracy: 0.8198\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2649 - accuracy: 0.8906 - val_loss: 0.3785 - val_accuracy: 0.8200\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2573 - accuracy: 0.8936 - val_loss: 0.3783 - val_accuracy: 0.8210\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2500 - accuracy: 0.8972 - val_loss: 0.3785 - val_accuracy: 0.8208\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2431 - accuracy: 0.9007 - val_loss: 0.3791 - val_accuracy: 0.8208\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2365 - accuracy: 0.9036 - val_loss: 0.3801 - val_accuracy: 0.8218\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2301 - accuracy: 0.9069 - val_loss: 0.3815 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04a42ea040>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01897d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
